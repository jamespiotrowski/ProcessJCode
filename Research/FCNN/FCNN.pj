import std.*;

/*
 * First, initialize weights with value that is (centered around value 0 with variance 1)
 * mean is 0, standard deviation is 1
 * https://www.socscistatistics.com/utilities/normaldistribution/default.aspx
 * https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php
 * 
 * then, multiply value by sqrt(1/n) where n is the number of inputs to the node
 * so, for a node in the first layer, it would be like (-0.2) * sqrt(1 / 728)
 * 
 * https://www.youtube.com/watch?v=8krd5qKVw-Q&t=352s
 * 
 * https://levelup.gitconnected.com/how-do-computers-generate-random-numbers-a72be65877f6
 * make a library for random numbers
 */

double xavierInitialization(int numInputs){
    return gaussianRandom() * sqrt(1.0 / (double)numInputs);
}

void FullyConnectedNeuralNetwork(const int inputSize, const int[] layerSizes){
    print("<FullyConnectedNeuralNetwork>: Creating Neural Network with input size: {" + inputSize + "} and shape: { ");
    for(int i = 0; i < layerSizes.size; i++){
        print(layerSizes[i] + " ");
    }
    println("}");

    /***************************** 
     * FCNN Stats
    *****************************/
    println("<FullyConnectedNeuralNetwork>: Creating network skeleton...");
    int numLayers = layerSizes.size;

    println("    - <FullyConnectedNeuralNetwork>: Allocating channels & weights...");
    chan<double>[][][] connections = new chan<double>[numLayers][0][0];
    double[][][] w = new double[numLayers][0][0];
    double[][][] wN = new double[numLayers][0][0];
    double[][] b = new double[numLayers][0];
    double[][] bN = new double[numLayers][0];
    double[][] s = new double[numLayers][0];
    double[][] y = new double[numLayers][0];
    double[][] errorStore = new double[numLayers][0];
    double[] error = new double[layerSizes[numLayers - 1]];

    for(int i = 0; i < numLayers; i++){
        // Dimensions
        int lowerSize = (i == 0) ? inputSize : layerSizes[i - 1];
        int upperSize = layerSizes[i];
        // Allocations
        connections[i] = new chan<double>[lowerSize][upperSize];
        w[i] = new double[lowerSize][upperSize];
        wN[i] = new double[lowerSize][upperSize];
        b[i] = new double[upperSize];
        bN[i] = new double[upperSize];
        s[i] = new double[upperSize];
        y[i] = new double[upperSize];
        errorStore[i] = new double[upperSize];
    }

    println("    - <FullyConnectedNeuralNetwork>: Checking allocations");
    println("        - <FullyConnectedNeuralNetwork>: connections: ");
    for(int i = 0; i < connections.size; i++){
        println("            - Layer " + i + ": { " + connections[i].size + " , " + connections[i][0].size + " }");
    }

    println("        - <FullyConnectedNeuralNetwork>: w: ");
    for(int i = 0; i < w.size; i++){
        println("            - Layer " + i + ": { " + w[i].size + " , " + w[i][0].size + " }");
    }

    println("        - <FullyConnectedNeuralNetwork>: wN: ");
    for(int i = 0; i < wN.size; i++){
        println("            - Layer " + i + ": { " + wN[i].size + " , " + wN[i][0].size + " }");
    }

    println("        - <FullyConnectedNeuralNetwork>: b: ");
    for(int i = 0; i < b.size; i++){
        println("            - Layer " + i + ": { " + b[i].size + " }");
    }

    println("        - <FullyConnectedNeuralNetwork>: bN: ");
    for(int i = 0; i < bN.size; i++){
        println("            - Layer " + i + ": { " + bN[i].size + " }");
    }

    println("        - <FullyConnectedNeuralNetwork>: s: ");
    for(int i = 0; i < s.size; i++){
        println("            - Layer " + i + ": { " + s[i].size + " }");
    }

    println("        - <FullyConnectedNeuralNetwork>: y: ");
    for(int i = 0; i < y.size; i++){
        println("            - Layer " + i + ": { " + y[i].size + " }");
    }

    println("        - <FullyConnectedNeuralNetwork>: errorStore: ");
    for(int i = 0; i < errorStore.size; i++){
        println("            - Layer " + i + ": { " + errorStore[i].size + " }");
    }

    println("        - <FullyConnectedNeuralNetwork>: error: ");
    println("            - { " + error.size + " }");
}

public void main(string[] args){
   

    int inputSize = 728;
    int numLayers = 3;
    
    int[] layers = new int[numLayers];
    layers[0] = 40; layers[1] = 20; layers[2] = 10;

    FullyConnectedNeuralNetwork(inputSize, layers);
    println(xavierInitialization(728));
    println(xavierInitialization(728));
    println(xavierInitialization(728));
    println(xavierInitialization(728));
    println(xavierInitialization(728));
    println(xavierInitialization(40));
    println(xavierInitialization(40));
    println(xavierInitialization(40));
    println(xavierInitialization(40));
    println(xavierInitialization(40));
    println(xavierInitialization(20));
    println(xavierInitialization(20));
    println(xavierInitialization(20));
    println(xavierInitialization(20));
    println(xavierInitialization(20));
    println(xavierInitialization(10));
    println(xavierInitialization(10));
    println(xavierInitialization(10));
    println(xavierInitialization(10));
    println(xavierInitialization(10));
}
